# -*- coding: utf-8 -*-
"""AIO-HW1-Module3 (Pandas)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_4_XxZfpolJlgKHKNPD5EAvhnMT4mkY8

## **A. Data Analysis with IMBD Movie Data**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

dataset_path = '/content/IMDB-Movie-Data.csv'

data = pd.read_csv(dataset_path)

# Read data with specified explicit index .
# We will use this later in our analysis

data_indexed = pd.read_csv(dataset_path, index_col = "Title")

print(data_indexed)

"""### **2.View data**"""

data.head()

"""### **3. Understand some basic information about the data**"""

data.info()

data.describe()

"""### **4. Data Selection - Indexing and Slicing Data**"""

genre = data['Genre']

print(genre)

# Extract data as dataframe

data[['Genre']]

some_cols = data[['Title','Genre','Actors','Director','Rating']]

print(some_cols)

## Slicing

data.iloc[10:15][['Title', 'Genre' , 'Rating','Revenue (Millions)']]

"""### **5. Data Selection - Based on Conditional filtering**"""

data[((data['Year'] >= 2010) & (data['Year'] <= 2015))
& (data['Rating'] < 6.0)
& (data['Revenue (Millions)'] > data['Revenue (Millions)'].quantile(0.95))]

"""### **6. Groupby Operations**"""

data.groupby('Director')[['Rating']].mean().head()

"""### **7. Sorting Operations**"""

data.groupby('Director')[['Rating']].mean().sort_values(['Rating'], ascending = False).head()

"""### **8. View missing values**"""

# To check null values row-wise

data.isnull().sum()

"""### **9. Deal with missing values - Deleting**"""

# Use drop function to drop columns

data.drop('Metascore', axis = 1).head()

data.dropna()

"""### **10. Dealing with missing values - Filling**"""

revenue_mean = data_indexed['Revenue (Millions)'].mean()

print("The mean revenue is: ", revenue_mean)

# We can fill the null values with this mean revenue

data_indexed['Revenue (Millions)'].fillna(revenue_mean, inplace = True)

"""### **11. apply() functions**"""

def rating_group(rating):
  if rating >= 7.5:
    return 'Good'

  elif rating >= 6.0:
    return 'Average'

  else:
    return 'Bad'

data['Rating_category'] = data['Rating'].apply(rating_group)

print(data[['Title', 'Director', 'Rating', 'Rating_category']].head())

"""## **B. Data Analysis with Time Series Data**"""

import pandas as pd

dataset_path = '/content/opsd_germany_daily.csv'

opsd_daily = pd.read_csv(dataset_path)

print(opsd_daily.shape)
print(opsd_daily.dtypes)

opsd_daily.head(3)

# Tạo thêm cột Year, Month, Weekday

opsd_daily = pd.read_csv('opsd_germany_daily.csv', index_col = 0, parse_dates = True)

opsd_daily['Year'] = opsd_daily.index.year

opsd_daily['Month'] = opsd_daily.index.month

opsd_daily['Weekday Name'] = opsd_daily.index.day_name()

opsd_daily.sample(5, random_state = 0)

"""### **2. Time-based indexing**"""

opsd_daily.loc['2014-01-20':'2014-01-22']

opsd_daily.loc['2012-02']

"""### **3. Visualizing time series data**"""

import matplotlib.pyplot as plt

import seaborn as sns

sns.set(rc = {'figure.figsize': (11,4)})

opsd_daily['Consumption'].plot(linewidth = 0.5)

cols_plot = ['Consumption', 'Solar', 'Wind']

axes = opsd_daily[cols_plot].plot(marker = '.', alpha = 0.5, linestyle = 'None',
                                  figsize = (11,9), subplots = True)

for ax in axes:
  ax.set_ylabel('Daily Totals (GWh)')

plt.show()

"""### **4. Seasonality**"""

fig, axes = plt.subplots(3, 1, figsize = (11, 10), sharex = True)

for name, ax in zip(['Consumption', 'Solar', 'Wind'], axes):
  sns.boxplot(data = opsd_daily, x = 'Month', y = name, ax = ax)
  ax.set_ylabel('GWh')
  ax.set_title(name)

  # Remove the automatic x-axis label from all but the bottom subplot

  if ax != axes[-1]:
    ax.set_xlabel('')

"""### **5. Frequencies**"""

pd.date_range('1998-03-10', '1998-03-15', freq = 'D')

## Sử dụng forward fill (ffill)

# To select an arbitrary sequence of date/time values from a pandas time series,
# we need to use a DatetimeIndex, rather than simply a list of date/time strings

times_sample = pd.to_datetime(['2013-02-03', '2013-02-06', '2013-02-08'])

# Select the specified dates and just the Consumption column

consum_sample = opsd_daily.loc[times_sample, ['Consumption']].copy()

consum_sample

# Convert the data to daily frequency, without filling any missings

consum_freq = consum_sample.asfreq('D')

# Create a column with missings forward filled

consum_freq['Consumption - Forward Fill'] = consum_sample.asfreq('D', method = 'ffill')

consum_freq

"""### **6. Resampling**"""

# Specify the data columns we want to include (i.e. exclude Year, Month, Weekday Name)

data_columns = ['Consumption', 'Wind', 'Solar', 'Wind+Solar']

# Resample to weekly frequency, aggregating with mean

opsd_weekly_mean = opsd_daily[data_columns].resample('W').mean()

opsd_weekly_mean.head(3)

#Start and end of the date range to extract
start, end = '2017-01', '2017-06'
# Plot daily and weekly resampled time series together
fig, ax = plt.subplots()
ax.plot(opsd_daily.loc[start:end, 'Solar'],
marker='.', linestyle='-', linewidth=0.5, label='Daily')
ax.plot(opsd_weekly_mean.loc[start:end, 'Solar'],
marker='o', markersize=8, linestyle='-', label='Weekly Mean Resample')
ax.set_ylabel('Solar Production (GWh)')
ax.legend()
plt.show()

# Compute the annual sums, setting the value to NaN for any year which has
# fewer than 360 days of data
opsd_annual = opsd_daily[data_columns].resample('Y').sum(min_count=360)
# The default index of the resampled DataFrame is the last day of each year,
# ('2006-12-31', '2007-12-31', etc.) so to make life easier, set the index
# to the year component
opsd_annual = opsd_annual.set_index(opsd_annual.index.year)
opsd_annual.index.name = 'Year'
# Compute the ratio of Wind+Solar to Consumption
opsd_annual['Wind+Solar/Consumption'] = opsd_annual['Wind+Solar'] / opsd_annual['Consumption']
opsd_annual.tail(3)

# Plot from 2012 onwards, because there is no solar production data in earlier years
ax = opsd_annual.loc[2012:, 'Wind+Solar/Consumption'].plot.bar(color='C0')
ax.set_ylabel('Fraction')
ax.set_ylim(0, 0.3)
ax.set_title('Wind + Solar Share of Annual Electricity Consumption')
plt.xticks(rotation=0)
plt.show()

"""### **7. Rolling Windows**"""

opsd_daily[data_columns].head(8)

#Compute the centered 7-day rolling mean
opsd_7d = opsd_daily[data_columns].rolling(7, center=True).mean()
opsd_7d.head(8)

"""### **9. Trends**"""

import matplotlib.dates as mdates

# The min_periods=360 argument accounts for a few isolated missing days in the
# wind and solar production time series
opsd_365d = opsd_daily[data_columns].rolling(
    window=365,
    center=True,
    min_periods=360
).mean()

# Plot daily, 7-day rolling mean, and 365-day rolling mean time series
fig, ax = plt.subplots()
ax.plot(opsd_daily['Consumption'], marker='.', markersize=2, color='0.6',
linestyle='None', label='Daily')
ax.plot(opsd_7d['Consumption'], linewidth=2, label='7-d Rolling Mean')
ax.plot(opsd_365d['Consumption'], color='0.2', linewidth=3,
label='Trend (365-d Rolling Mean)')
# Set x-ticks to yearly interval and add legend and labels
ax.xaxis.set_major_locator(mdates.YearLocator())
ax.legend()
ax.set_xlabel('Year')
ax.set_ylabel('Consumption (GWh)')
ax.set_title('Trends in Electricity Consumption')
plt.show()

# Plot 365-day rolling mean time series of wind and solar power
fig, ax = plt.subplots()
for nm in ['Wind', 'Solar', 'Wind+Solar']:
    ax.plot(opsd_365d[nm], label=nm)
    # Set x-ticks to yearly interval, adjust y-axis limits, add legend and labels
    ax.xaxis.set_major_locator(mdates.YearLocator())
    ax.set_ylim(0, 400)
    ax.legend()
    ax.set_ylabel('Production (GWh)')
    ax.set_title('Trends in Electricity Production (365-d Rolling Means)')
plt.show()